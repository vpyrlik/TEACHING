---
title: "Разбор эмпирического задания к семинару 5"
date: '2022-10-04'
output:  
  html_document:  
    self_contained: no  
    theme: cosmo
    toc: true
    toc_float: true
    toc_collapsed: true
    toc_depth: 2
mainfont: Liberation Serif
monofont: Liberation Mono
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Уважаемые студенты! В этой файле представлен *частичный* разбор задания к семинару 5. Основная цель --- закрепить навыки расчета робастных стандартных ошибок и построения таблиц для сопоставления результатов нескольких регрессий. **Разбор этого примера не освобождает от необходимости решения других заданий семинара, если вы их еще не выполнили.**

## Загрузка пакетов

Сначала загружаем необходимые пакеты.

```{r, message=FALSE}
library(wooldridge)   # наборы данных, используемые в учебнике Wooldridge
library(dplyr)        # манипуляции с данными
library(lmtest)       # тестирование гипотез
library(sandwich)     # робастные стандартные ошибки
library(stargazer)    # представление результатов нескольких регрессий в одной таблице
library(modelsummary) # более современный пакет для представления результатов регрессий
```


## Набор данных

Мы работаем с данными ["discrim"](https://www.rdocumentation.org/packages/wooldridge/versions/1.4-2/topics/discrim). Фрагмент данных можно загрузить, используя встроенный набор данных пакета [wooldridge](https://www.rdocumentation.org/packages/wooldridge/versions/1.4-2).

Оригинальное исследование, на данные которого мы опираемся, описано в статье **Graddy, K. (1997). Do fast-food chains price discriminate on the race and income characteristics of an area?. Journal of Business & Economic Statistics, 15(4), 391-401**.

```{r}
data("discrim")
discrim %>% glimpse()
```


## Предварительная обработка данных

При ознакомлении с данными вы можете заметить, что характеристики заведений фастфуда собирались в две волны, в то время как характеристики районов постоянны. Для сопоставимости создадим переменные, равные средним за две волны значениям необходимых переменных. 

Также заметим, что переменная дохода выражена в долларах, т. е. включается в себя довольно крупные значения. Для наглядности можно перевести ее в тысячи долларов. Тоже самое касается стоимости недвижимости. 

```{r}
discrim <- discrim %>% mutate(psoda_av = (psoda + psoda2) / 2,
                              pfries_av = (pfries + pfries2) / 2,
                              pentree_av = (pentree + pentree2) / 2,
                              wagest_av = (wagest + wagest2) / 2,
                              emp_av = (emp + emp2) / 2,
                              income_thou = income / 1000,
                              hseval_thou = hseval / 1000)
```


## Регрессионный анализ

### Подробный разбор первой парной регрессии

Для примера в качестве зависимой переменной мы возьмем цену газировки (`psoda_av`), но помните, что полноценный анализ предполагал бы еще и рассмотрение других ценовых переменных. 

Начинаем с парных регрессий. Сначала рассмотрим регрессию цены газировки на долю афроамериканцев среди жителей района. 

```{r}
msoda1 <- lm(psoda_av ~ 1 + prpblck, data = discrim)
```

Для расчета робастных стандартных ошибок создадим ковариационную матрицу оценок коэффициентов. Для этого воспользуемся функцией `vcocHC()` из пакета `sandwich`. 

```{r}
cov_msoda1 <- vcovHC(msoda1, type = "HC0")
cov_msoda1
```

Заметьте, что эта матрица рассчитана не по той формуле, которая дается вам в материалах курса, но нам важно то, что если мы извлечем квадратный корень из ее диагональных элементов, мы получим вектор стандартных ошибок для оцененных коэффициентов регрессии.

```{r}
se_msoda1 <- sqrt(diag(cov_msoda1))
se_msoda1
```

Мы также можем автоматически провести тест на значимость коэффицентов, используя функция `coeftest()` из пакета `lmtest`. 

```{r}
coeftest(msoda1, df = Inf, vcov = cov_msoda1)
```


### Остальные регрессии

Повторим без подробного обсуждения все эти действия для оценки еще нескольких моделей.

Сначала рассмотрим регрессию цены газировки на медианный доход семьи в районе. 

```{r}
msoda2 <- lm(psoda_av ~ 1 + income_thou, data = discrim) 
cov_msoda2 <- vcovHC(msoda2, type = "HC0")
se_msoda2 <- sqrt(diag(cov_msoda2))
```

После оценки базовых парных регрессий две переменные интереса (`prpblck` и `income`) можно объединить в одну модель. Туда же можно добавить еще одну переменную, связанную с доходом --- `prppov` (доля бедных).

```{r}
msoda3 <- lm(psoda_av ~ 1 + prpblck + income_thou + prppov, data = discrim) 
cov_msoda3 <- vcovHC(msoda3, type = "HC0")
se_msoda3 <- sqrt(diag(cov_msoda3))
```

Более того, для решения проблемы смещения из-за пропущенных переменных, модели нужно расширять путем добавления в них контрольных переменных. 

Добавим в качестве контрольных переменные, связанные с издержками. 

```{r}
msoda4 <- lm(psoda_av ~ 1 + prpblck + income_thou + prppov + wagest_av + emp_av + crmrte + hseval_thou, 
             data = discrim) 
cov_msoda4 <- vcovHC(msoda4, type = "HC0")
se_msoda4 <- sqrt(diag(cov_msoda4))
```

Далее добавим в качестве контрольных переменные, связанные с конкуренцией. 

```{r}
msoda5 <- lm(psoda_av ~ 1 + prpblck + income_thou + prppov + compown + prpncar + nstores, 
             data = discrim) 
cov_msoda5 <- vcovHC(msoda5, type = "HC0")
se_msoda5 <- sqrt(diag(cov_msoda5))
```

Наконец, оценким регрессию, включающую все переменные интереса и все контрольные переменные из предыдущих регрессиий.

```{r}
msoda6 <- lm(psoda_av ~                                     # зависимая переменная
               1 +                                          # константа
               prpblck + income_thou + prppov +             # переменные интереса
               wagest_av + emp_av + crmrte + hseval_thou +  # контрольные переменные, связанные с издержками
               compown + prpncar + nstores,                 # контрольные переменные, связанные с конкуренцией
             data = discrim) 
cov_msoda6 <- vcovHC(msoda6, type = "HC0")
se_msoda6 <- sqrt(diag(cov_msoda6))
```


## Представление результатов регрессий в одной таблице

Здесь мы покажем два способа свести результаты нескольких регрессий в одну таблицу: функцию `modelsummary()` из пакета `modelsummary`, а также функцию `stargazer()` из пакета `stargazer`. Обе функции обладают огромным числом аргументов, т. е. вид таблиц можно очень гибко настраивать. Здесь будут показаны только базовые варианты использования этих функций. 

### modelsummary

```{r}
modelsummary(models = list(msoda1, msoda2, msoda3, 
                           msoda4, msoda5, msoda6),                       # список оцененных моделей
             vcov = list(cov_msoda1, cov_msoda2, cov_msoda3, 
                         cov_msoda4, cov_msoda5, cov_msoda6),             # список ковариционных матриц для расчета стандартных ошибок
             statistic = "std.error",                                     # выводить стандартные ошибки
             stars = TRUE,                                                # звездочки для уровня значимости
             gof_omit = ".*",                                             # не выводить никаких показателей качества моделей
             notes = list("В скобках даны робастные стандартные ошибки"), # комментарий по поводу расчета стандартных ошибок
             title = "Результаты оценки")                                 # заголовок таблицы
```


### stargazer

```{r}
stargazer(msoda1, msoda2, msoda3, 
          msoda4, msoda5, msoda6,                                # список оцененных моделей
          se = list(se_msoda1, se_msoda2, se_msoda3, 
                    se_msoda4, se_msoda5, se_msoda6),            # список векторов стандартных ошибок
          title = "Результаты оценки",                           # заголовок таблицы
          keep.stat = "n",                                       # оставить только число наблюдений для характеристики моделей
          notes = "В скобках даны робастные стандартные ошибки", # комментарий по поводу расчета стандартных ошибок
          type = 'text')
```


## Выводы

Выводы делайте сами. ;)